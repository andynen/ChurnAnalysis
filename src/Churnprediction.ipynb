{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "In this tutorial, you will learn how to analyse and predict churn data using Scikit-learn, \n",
    "telecommunication data, and SMOTE. Specifically, how to: \n",
    "\n",
    "Work on a project approach\n",
    "Automate the exploratory analysis of churn data\n",
    "Use Scikit-learn to predict customer churn using telecommunication data \n",
    "Create detailed explicit functions \n",
    "How to deal with Imbalanced data using SMOTE\n",
    "Metrics appropriate for imbalance data prediction\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Import packages \"\"\"\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno as msno   # To assess missing values pattern\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, precision_recall_curve, auc\n",
    "\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Load the data \"\"\"\n",
    "# Path to the data folder\n",
    "dataf = os.path.join(os.getcwd(), os.pardir, \"data\")\n",
    "\n",
    "# name of the csv file\n",
    "csv_file = \"WA_Fn-UseC_-Telco-Customer-Churn.csv\"\n",
    "\n",
    "# Load the csv file\n",
    "churndf = pd.read_csv( os.path.join(dataf, csv_file) )\n",
    "\n",
    "churndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Data cleaning \n",
    "Some numeric columns have a different data type, let's create a function that converts \n",
    "specified columns in a given data frame to numeric data type.\n",
    "\"\"\"\n",
    "\n",
    "# Convert columns to numeric\n",
    "from convert_col_to_numeric import convert_col_to_numeric\n",
    "churndf = convert_col_to_numeric( df = churndf, columns = [\"TotalCharges\", \"MonthlyCharges\" ] )\n",
    "\n",
    "# Check and remove NAs\n",
    "print( churndf.isnull().sum() )  # Missing values per column\n",
    "churndf = churndf.dropna()       # Remove rows with missing values\n",
    "churndf.isnull().sum()           # Verify if they are removed\n",
    "\n",
    "# Drop the customerID  as it is not needed in the analysis\n",
    "churndf = churndf.drop(['customerID'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Data Characteristics \"\"\"\n",
    "\n",
    "from data_characteristics import data_characteristics\n",
    "print( data_characteristics( df = churndf ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" EDA : Exploratory data analysis \n",
    "\"\"\"\n",
    "\n",
    "# the column SeniorCitizen is a catgorical variable, but is encoded as \n",
    "#boolean values which might be misleading Python to consider it as numerical. \n",
    "#Let's code it as follows: 0 as No, and 1 as Yes\n",
    "churndf[\"SeniorCitizen\"]= churndf[\"SeniorCitizen\"].map({0: \"No\", 1: \"Yes\"})\n",
    "\n",
    "from automated_eda_plotly import automated_eda_plotly\n",
    "automated_eda_plotly(data=churndf, target_var=\"Churn\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Data preprocessing\n",
    "\n",
    "Note that this prediction process we will use random forest classifier from Scikit-learn package\n",
    "\n",
    "In this analysis we are dealing with categorical data some are binary and other nominal. and because we are mainly\n",
    "using an ML algorithm that relies on numerical computations encoding the categorical variable is our next step. \n",
    "\"\"\"\n",
    "\n",
    "from label_encode_columns import label_encode_columns\n",
    "from convert_to_binary import convert_to_binary\n",
    "\n",
    "cols_to_label_encode = [ 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "                        'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaymentMethod']\n",
    "cols_to_convert_to_binary = [ 'gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'PaperlessBilling', 'Churn' ]\n",
    "\n",
    "# Convert categorical variables to label encoded using the function label_encode_columns\n",
    "churndf_copy = churndf\n",
    "churndf_copy = label_encode_columns( churndf_copy, cols_to_label_encode)\n",
    "churndf_copy = convert_to_binary( churndf_copy, cols_to_convert_to_binary)\n",
    "\n",
    "# Check if the conversion worked as expected. \n",
    "churndf_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Churn data prediction using random forest\n",
    "'''\n",
    "\n",
    "# First, let's split the data into train and test. Where the former is used to learn teh relationship between teh features and the Churn variable, \n",
    "# and the latter is used to evaluate the performance of the model. Let's use the function split_dataset\n",
    "from split_dataset import split_dataset\n",
    "\n",
    "SEED = 50\n",
    "X_train, X_test, Y_train, Y_test = split_dataset(df = churndf_copy, target_column = 'Churn', test_size=0.2, random_state=SEED)\n",
    "\n",
    "# Next, let's create an instance of the random forest model with some specific hyperparameter values using the function fit_rf_model\n",
    "from build_rf_model import build_rf_model\n",
    "\n",
    "\n",
    "churn_rf_model = build_rf_model( X_train, Y_train, n_estimators=500, oob_score=True, n_jobs=4, \n",
    "              random_state=SEED, max_features=\"sqrt\", max_leaf_nodes=30 )\n",
    "\n",
    "# Then let's evaluate the fitted model to find out whether it makes accurate prediction. \n",
    "from assess_model_accuracy import assess_model_accuracy\n",
    "accuracy = assess_model_accuracy(churn_rf_model, X_test, Y_test)\n",
    "\n",
    "print(f\"The accuracy of the fitted model: {accuracy['accuracy']:.2f}\")\n",
    "\n",
    "# Also plot the confusion matrix to evealuate which label were predicted better / worst\n",
    "from plot_confusion_matrix import plot_confusion_matrix\n",
    "plot_confusion_matrix(Y_test, accuracy['predictions'], \n",
    "                      title=\"RF confusion matrix\")\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report( Y_test, accuracy['predictions'] ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Let's evaluate the model using alternative metrics like ROC-AUC and PR-AUC  \"\"\"\n",
    "    \n",
    "from evaluate_model_probabilities import evaluate_model_probabilities\n",
    "\n",
    "# Compute ROC-AUC & PR-AUC and plot the precision-recall curve using the function evaluate_model_probabilities\n",
    "roc_pr_auc = evaluate_model_probabilities(churn_rf_model, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Synthesize new training samples using SMOTE \"\"\"\n",
    "\n",
    "from apply_smote import apply_smote\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "X_train_new, Y_train_new = apply_smote(X_train, Y_train, seed=SEED, k_neighbors= 5)\n",
    "\n",
    "# Combine features and target into one DataFrame\n",
    "smote_churndf  = pd.concat([X_train_new, Y_train_new], axis=1)\n",
    "\n",
    "# Carry out a new EDA to evaluate the distribution of the Churn variable in relation to the feastures \n",
    "automated_eda_plotly(data=smote_churndf, target_var=\"Churn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Churn data prediction using random forest\n",
    "\n",
    "\"\"\"\n",
    "churn_rf_mod_new = build_rf_model( X_train_new, Y_train_new, n_estimators=50, oob_score=True, n_jobs=4, \n",
    "              random_state=SEED, max_features=\"sqrt\", max_leaf_nodes=30 )\n",
    "\n",
    "# Then let's evaluate the fitted model to find out whether it makes accurate prediction. \n",
    "accuracy_new = assess_model_accuracy(churn_rf_mod_new, X_test, Y_test)\n",
    "\n",
    "print(f\"The accuracy of the fitted model: {accuracy_new['accuracy']:.2f}\")\n",
    "\n",
    "# Also plot the confusion matrix to evealuate which label were predicted better / worst\n",
    "plot_confusion_matrix(Y_test, accuracy_new['predictions'], \n",
    "                      title=\"RF confusion matrix\")\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report( Y_test, accuracy_new['predictions'] ))\n",
    "\n",
    "# The precision-recal curve\n",
    "from evaluate_model_probabilities import evaluate_model_probabilities\n",
    "\n",
    "# Compute ROC-AUC & PR-AUC and plot the precision-recall curve using the function evaluate_model_probabilities\n",
    "roc_pr_auc = evaluate_model_probabilities(churn_rf_mod_new, X_test, Y_test)\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "Thank you for following through till the end. I look forward to receiving your feedback and earring more about how this blog was helpful to you. \n",
    "Do reach out if you have got any question. \n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
